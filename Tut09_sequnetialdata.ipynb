{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 09: Sequential Datasets\n",
    "\n",
    "\n",
    "A sequential dataset refers to data that is ordered or time-dependent. Examples include:\n",
    "\n",
    "- Time series data (e.g., stock prices, weather patterns)\n",
    "- Natural language (e.g., sentences or paragraphs in text data)\n",
    "- Video frames (e.g., frames in a video that need to be processed in sequence)\n",
    "\n",
    "In these cases, the order of data matters because the previous data points influence the interpretation of the next ones. For instance, in a language model, the words preceding a certain word help predict that word, and in time series forecasting, the past values influence the future prediction.\n",
    "\n",
    "---\n",
    "\n",
    "### Training Data in Sequential Datasets\n",
    "\n",
    "When working with sequential data, it’s essential to structure the training data properly to respect the temporal order. In PyTorch, this can be achieved by creating a custom Dataset class that handles the specific needs of sequential data. For instance, we might want to split a sequence into overlapping chunks where each chunk is used to predict the next time step or sequence of time steps.\n",
    "\n",
    "Here’s an example of how this might work:\n",
    "\n",
    "- **Data Transformation**: In a sequential dataset, each sequence might be divided into fixed-length subsequences (e.g., sliding windows). Each subsequence is treated as a sample in the dataset.\n",
    "\n",
    "- **Input-Output Pairs**: The data might be structured as input-output pairs, where the input consists of several previous time steps, and the output is the subsequent time step(s).\n",
    "\n",
    "- **Sliding Window**: A sliding window approach allows us to generate sequences of data that can be fed into the model. This is particularly useful in time series data where we use a sliding window to predict future values based on past observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "input sample: [ 1.07  0.1   0.41 -1.83 -0.64 -1.71  0.14 -0.1  -0.34 -0.46]\n",
      "output sample: [-0.27  0.12  0.75 -2.17 -0.62]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SequentialDataset(Dataset):\n",
    "    def __init__(self, data, seq_len, label_len):\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len - self.label_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Create sequences from the data\n",
    "        seq_x = self.data[index:index + self.seq_len]\n",
    "        seq_y = self.data[index + self.seq_len:index + self.seq_len + self.label_len]\n",
    "        \n",
    "        return seq_x, seq_y\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = torch.randn(100, 1)  \n",
    "dataset = SequentialDataset(data, seq_len=10, label_len=5)\n",
    "print(data.shape)\n",
    "\n",
    "seq_x, seq_y = dataset[0] \n",
    "print(f\"input sample: {np.round(seq_x.detach().flatten().tolist(),2)}\")\n",
    "print(f\"output sample: {np.round(seq_y.detach().flatten().tolist(),2)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
