{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 05: Loading the checkpoints and Testing Models \n",
    "\n",
    "In this tutorial, we'll go over how to load a saved model checkpoint and test it on a dataset. Checkpoints are useful for saving the progress of training and resuming later, or for testing a trained model on unseen data. Weâ€™ll use PyTorch to demonstrate how to save, load, and test a model.\n",
    "\n",
    "1. **Saving the entire model**\n",
    "2. **Saving only the model parameters (state_dict)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath, weights_only=True)  \n",
    "    input_size = checkpoint['input_size']\n",
    "    output_size = checkpoint['output_size']\n",
    "    hidden_layers = checkpoint['hidden_layers']\n",
    "\n",
    "    # Recreate the model with nn.Sequential based on the saved architecture\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_layers[0]),  \n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layers[0], output_size)  \n",
    "    )\n",
    "    \n",
    "    # Load the saved model state_dict (weights)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    # Set the model to evaluation mode (optional, but recommended for inference)\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model_path = \"./models/test_model.pth\"\n",
    "loaded_model = load_checkpoint(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on unseen data: tensor([30.4847, 19.7615, 34.5468, 24.9005, 22.3329])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "unseen_data = pd.DataFrame({\n",
    "    \"x1\": [2.0, 3.5, 1.8, 2.5, 3.0],\n",
    "    \"x2\": [3000, 4000, 2800, 3500, 3700],\n",
    "    \"x3\": [4, 6, 4, 6, 6]   \n",
    "})\n",
    "\n",
    "# Normalize the unseen data (same way as you normalized the training data)\n",
    "X_unseen = unseen_data.values\n",
    "X_unseen_normalized = (X_unseen - X_unseen.mean(axis=0)) / X_unseen.std(axis=0)\n",
    "\n",
    "# Convert to tensor\n",
    "X_unseen_tensor = torch.tensor(X_unseen_normalized, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    predictions = loaded_model(X_unseen_tensor)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions on unseen data:\", predictions.detach().flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
