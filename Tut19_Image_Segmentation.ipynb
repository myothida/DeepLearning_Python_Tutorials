{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64bf612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import SAM\n",
    "import numpy as np\n",
    "\n",
    "model = SAM('sam_b.pt')\n",
    "\n",
    "image_path = './data/test_img_R.jpg' \n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "results = model(image_rgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ce852",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results and results[0].masks is not None:\n",
    "    # Get the raw masks as a numpy array (HxWxN, where N is number of masks)\n",
    "    masks_tensor = results[0].masks.data\n",
    "    masks_np = masks_tensor.cpu().numpy() # Move to CPU and convert to NumPy\n",
    "\n",
    "    # Create a blank image to draw all masks on\n",
    "    masked_image = np.zeros_like(image_rgb, dtype=np.uint8)\n",
    "\n",
    "    # You can iterate through masks and draw them with random colors\n",
    "    for i, mask in enumerate(masks_np):\n",
    "        color = np.random.randint(0, 255, 3, dtype=np.uint8)\n",
    "        # Apply the mask: wherever mask is True, apply the color\n",
    "        masked_image[mask] = color\n",
    "\n",
    "    # You can blend the original image with the masks for a better visualization\n",
    "    alpha = 0.5 # Transparency of the masks\n",
    "    blended_image = cv2.addWeighted(image_rgb, 1, masked_image, alpha, 0)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(blended_image)\n",
    "    plt.title(\"Segmented Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Found {len(masks_np)} segments.\")\n",
    "\n",
    "else:\n",
    "    print(\"No segments found or an issue occurred during segmentation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d843a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import os # For creating a directory to save images\n",
    "\n",
    "# Create a directory to save the images\n",
    "output_dir = \"dbscan_demo_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"Calculates the Euclidean distance between two points.\"\"\"\n",
    "    return np.sqrt(np.sum((point1 - point2)**2))\n",
    "\n",
    "def find_neighbors(data, point_idx, eps):\n",
    "    \"\"\"Finds all points within the epsilon radius of a given point.\"\"\"\n",
    "    neighbors = []\n",
    "    for i in range(data.shape[0]):\n",
    "        if i == point_idx: # A point is always its own neighbor for distance 0\n",
    "            continue\n",
    "        if euclidean_distance(data[point_idx], data[i]) <= eps:\n",
    "            neighbors.append(i)\n",
    "    return neighbors\n",
    "\n",
    "def plot_current_state(data, labels, core_point_indices, title, filename, show_neighbor_counts=None):\n",
    "    \"\"\"Helper function to plot the current state of DBSCAN.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    unique_labels = set(labels)\n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:  # Noise points\n",
    "            col = 'k' # Black for noise\n",
    "            marker = 'x'\n",
    "            ms = 8\n",
    "            label_text = 'Noise'\n",
    "        else:\n",
    "            marker = 'o'\n",
    "            ms = 10 # Slightly larger for demo clarity\n",
    "            label_text = f'Cluster {k}'\n",
    "\n",
    "        class_member_mask = (labels == k)\n",
    "        xy = data[class_member_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], marker, markerfacecolor=col,\n",
    "                 markeredgecolor='k', markersize=ms, label=label_text)\n",
    "    \n",
    "    # Highlight core points with a red circle outline\n",
    "    if core_point_indices:\n",
    "        core_points_data = data[list(core_point_indices)]\n",
    "        plt.plot(core_points_data[:, 0], core_points_data[:, 1], 'o', markerfacecolor='none',\n",
    "                 markeredgecolor='red', markersize=16, linewidth=2, label='Core Points', linestyle='none')\n",
    "    \n",
    "    # Add neighbor counts if provided\n",
    "    if show_neighbor_counts is not None:\n",
    "        for i, count in enumerate(show_neighbor_counts):\n",
    "            if count is not None: # Only show for points where count was calculated\n",
    "                plt.text(data[i, 0] + 0.1, data[i, 1] + 0.1, str(count), fontsize=9, color='blue', ha='left', va='bottom')\n",
    "\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "    plt.grid(True)\n",
    "    plt.axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
    "    plt.savefig(os.path.join(output_dir, filename))\n",
    "    plt.close() # Close the plot to free memory\n",
    "\n",
    "def dbscan_step_demo(data, eps, min_pts):\n",
    "    \"\"\"\n",
    "    DBSCAN demonstration saving images at key steps.\n",
    "    \"\"\"\n",
    "    n_points = data.shape[0]\n",
    "    labels = np.full(n_points, 0, dtype=int)  # 0 for unclassified initially\n",
    "    visited = np.full(n_points, False, dtype=bool)\n",
    "    cluster_id = 0\n",
    "    core_point_indices = set()\n",
    "    all_neighbor_counts = [None] * n_points # To store neighbor counts for demo display\n",
    "\n",
    "    print(f\"--- DBSCAN Process with eps={eps}, MinPts={min_pts} ---\")\n",
    "\n",
    "    # --- Step 0: Initial State ---\n",
    "    plot_current_state(data, labels, core_point_indices, \n",
    "                       f'DBSCAN Demo: Initial State (eps={eps}, MinPts={min_pts})', \n",
    "                       'step_0_initial_state.png')\n",
    "    print(\"Saved: step_0_initial_state.png\")\n",
    "\n",
    "    # --- Step 1: Identify All Core Points ---\n",
    "    temp_core_point_indices = set()\n",
    "    print(\"\\n--- Phase 1: Identifying all potential Core Points ---\")\n",
    "    for i in range(n_points):\n",
    "        print(f\"Checking Point {i}: {data[i]}\")\n",
    "        current_neighbors = find_neighbors(data, i, eps)\n",
    "        # Include the point itself in the count for core point definition\n",
    "        current_neighbor_count = len(current_neighbors) + 1\n",
    "        all_neighbor_counts[i] = current_neighbor_count # Store count for plotting\n",
    "\n",
    "        if current_neighbor_count >= min_pts:\n",
    "            print(f\"  - Point {i} IS a **CORE POINT** (Neighbors: {current_neighbor_count} >= MinPts: {min_pts})\")\n",
    "            temp_core_point_indices.add(i)\n",
    "        else:\n",
    "            print(f\"  - Point {i} is NOT a core point (Neighbors: {current_neighbor_count} < MinPts: {min_pts})\")\n",
    "    \n",
    "    # Update actual core_point_indices after checking all points\n",
    "    core_point_indices = temp_core_point_indices.copy()\n",
    "\n",
    "    plot_current_state(data, labels, core_point_indices,\n",
    "                       f'DBSCAN Demo: Identified All Core Points (eps={eps}, MinPts={min_pts})',\n",
    "                       'step_1_all_core_points_identified.png',\n",
    "                       show_neighbor_counts=all_neighbor_counts)\n",
    "    print(\"Saved: step_1_all_core_points_identified.png\")\n",
    "\n",
    "\n",
    "    # --- Step 2: Cluster Expansion ---\n",
    "    print(\"\\n--- Phase 2: Expanding Clusters ---\")\n",
    "    first_cluster_expanded = False\n",
    "\n",
    "    for i in range(n_points):\n",
    "        if visited[i]:\n",
    "            continue # Skip if already visited/assigned to a cluster\n",
    "\n",
    "        visited[i] = True\n",
    "        \n",
    "        if i in core_point_indices: # Only core points can initiate a new cluster expansion\n",
    "            cluster_id += 1\n",
    "            labels[i] = cluster_id\n",
    "            \n",
    "            # Find neighbors again as find_neighbors excludes self\n",
    "            current_neighbors_for_queue = find_neighbors(data, i, eps)\n",
    "            queue = deque(current_neighbors_for_queue)\n",
    "\n",
    "            print(f\"\\nExpanding Cluster {cluster_id} from Core Point {i}\")\n",
    "\n",
    "            while queue:\n",
    "                current_expand_idx = queue.popleft()\n",
    "                \n",
    "                # If this point was unclassified noise (-1), mark it as visited and assign\n",
    "                if labels[current_expand_idx] == 0: # Check if it's currently unclassified\n",
    "                    visited[current_expand_idx] = True\n",
    "                    labels[current_expand_idx] = cluster_id\n",
    "                    print(f\"  - Point {current_expand_idx} assigned to Cluster {cluster_id}.\")\n",
    "\n",
    "                    # If this newly assigned point is also a core point, add its neighbors to queue\n",
    "                    if current_expand_idx in core_point_indices:\n",
    "                        print(f\"    - Point {current_expand_idx} is also a CORE POINT. Adding its unvisited neighbors to queue.\")\n",
    "                        expand_neighbors = find_neighbors(data, current_expand_idx, eps)\n",
    "                        for neighbor_of_expand_idx in expand_neighbors:\n",
    "                            if not visited[neighbor_of_expand_idx] and labels[neighbor_of_expand_idx] == 0: # Add only unvisited and unclassified points\n",
    "                                queue.append(neighbor_of_expand_idx)\n",
    "                \n",
    "            # --- Save state after first cluster is formed ---\n",
    "            if not first_cluster_expanded:\n",
    "                plot_current_state(data, labels, core_point_indices,\n",
    "                                   f'DBSCAN Demo: After First Cluster Formed (Cluster {cluster_id})',\n",
    "                                   f'step_2_cluster_{cluster_id}_formed.png',\n",
    "                                   show_neighbor_counts=all_neighbor_counts)\n",
    "                print(f\"Saved: step_2_cluster_{cluster_id}_formed.png\")\n",
    "                first_cluster_expanded = True # Flag to ensure this step is saved only once\n",
    "\n",
    "        else: # Not a core point\n",
    "            # If a point is not a core point and hasn't been visited by a core point's expansion, it's noise\n",
    "            if labels[i] == 0: # If still unclassified (not assigned by another core point)\n",
    "                labels[i] = -1 # Mark as noise\n",
    "                print(f\"  - Point {i} is not a core point and was not assigned. Marked as NOISE.\")\n",
    "\n",
    "    # --- Step 3: Final State ---\n",
    "    # Any remaining 0 labels should become -1 (noise)\n",
    "    labels[labels == 0] = -1\n",
    "\n",
    "    plot_current_state(data, labels, core_point_indices,\n",
    "                       f'DBSCAN Demo: Final Clustering Result (eps={eps}, MinPts={min_pts})',\n",
    "                       'step_3_final_result.png',\n",
    "                       show_neighbor_counts=all_neighbor_counts)\n",
    "    print(\"Saved: step_3_final_result.png\")\n",
    "\n",
    "    print(\"\\n--- DBSCAN Process Complete ---\")\n",
    "    return labels, core_point_indices\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Generate a smaller, clearer sample data\n",
    "    np.random.seed(0) # for reproducibility\n",
    "\n",
    "    # Cluster 1\n",
    "    c1 = np.array([[1, 1], [1.2, 1.2], [0.9, 0.8], [1.1, 0.9], [0.8, 1.1]])\n",
    "    # Cluster 2\n",
    "    c2 = np.array([[-1, -1], [-0.8, -1.2], [-1.1, -0.9], [-0.9, -0.8], [-1.2, -1.1]])\n",
    "    # Border point for C1\n",
    "    border_point_c1 = np.array([[1.5, 1.5]])\n",
    "    # Noise point\n",
    "    noise_point = np.array([[3, -3]])\n",
    "    # Another small group that might be noise or another cluster depending on params\n",
    "    c3 = np.array([[0, -2], [0.2, -2.1], [-0.1, -1.9]])\n",
    "\n",
    "\n",
    "    data = np.vstack((c1, c2, border_point_c1, noise_point, c3))\n",
    "    \n",
    "    # 2. Set DBSCAN parameters\n",
    "    # Adjust these to see how different core points and clusters form\n",
    "    eps = 0.5  # Epsilon: radius of neighborhood\n",
    "    min_pts = 4 # MinPts: minimum number of points in a neighborhood (including itself) to be a core point\n",
    "\n",
    "    print(f\"--- Running DBSCAN Demo with {len(data)} data points ---\")\n",
    "    print(f\"Data Points:\\n{data}\")\n",
    "\n",
    "    # 3. Run the DBSCAN demo\n",
    "    labels, core_point_indices = dbscan_step_demo(data, eps, min_pts)\n",
    "\n",
    "    # 4. Print Summary\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = list(labels).count(-1)\n",
    "    print(f\"\\n--- Final Summary ---\")\n",
    "    print(f\"Estimated number of clusters: {n_clusters}\")\n",
    "    print(f\"Estimated number of noise points: {n_noise}\")\n",
    "    print(f\"Total core points identified: {len(core_point_indices)}\")\n",
    "    print(f\"Check the '{output_dir}' directory for step-by-step images.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
