{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 1**: Load the Dataset\n",
    "\n",
    "Load the MNIST dataset and inspect the data structure.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- Load the dataset using the provided data loader.\n",
    "- Explore the dimensions of the training dataset.\n",
    "---\n",
    "\n",
    "#### **Step 2**: Preprocess the Data\n",
    "Prepare the data for training by normalizing pixel values and converting data into tensors.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- Convert the dataset into PyTorch tensors.\n",
    "- Normalize the pixel values to a range of -1 to 1. (mean =0.5, std = 0.5)\n",
    "- Visualize a few sample images along with their labels.\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: mnist...\n",
      "MNIST dataset already downloaded\n",
      "<class 'torch.Tensor'>\n",
      "Image dimenstion: torch.Size([1, 28, 28])\n",
      "Number of images in the 1st batch set: 64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import data_loader as dl\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_loader = dl.DataLoader()\n",
    "mnist_trdata, mnist_testdata = data_loader.get_dataset(\"mnist\")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(mnist_trdata, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(mnist_testdata, batch_size=64, shuffle=True)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(type(images))\n",
    "print(f\"Image dimenstion: {images.shape[1:]}\")\n",
    "print(f\"Number of images in the 1st batch set: {labels.shape[0]}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))  \n",
    "for k in range(3):\n",
    "    axes[k].imshow(images[k].numpy().squeeze(), cmap='Greys_r')  \n",
    "    axes[k].set_title(f\"Image label is {labels[k]}\")\n",
    "    axes[k].axis('off')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 3**: Build the Neural Network\n",
    "Define a neural network to classify the digits.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- Design a network architecture with \n",
    "    - **Input Layer**: 784 input units (corresponding to flattened 28x28 pixel images).\n",
    "    - **First hidden layer** with 128 units.\n",
    "    - **Second hidden layer** with 64 units.\n",
    "    - **Output Layer**: - 10 units (corresponding to the 10 possible digit classes: 0â€“9).\n",
    "-  Use **ReLU** (Rectified Linear Unit) for the two hidden layers to introduce non-linearity.\n",
    "-  Use **Softmax** for the output layer to produce probabilities for each digit class.\n",
    "- Create the neural network structure based on the above specifications and Initialize the model.\n",
    "- Before training the model, test its forward pass using a single input image to verify that the network is functioning as expected.\n",
    "- Visualize the the output using **helper module**.\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 2 with shape (784,) and arg 3 with shape (10,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m ps \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(images[img_idx,:])\n\u001b[0;32m     15\u001b[0m img \u001b[38;5;241m=\u001b[39m images[img_idx]\n\u001b[1;32m---> 16\u001b[0m \u001b[43mview_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_classify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe highest probablity \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mps\u001b[38;5;241m.\u001b[39mtopk(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% at class: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mps\u001b[38;5;241m.\u001b[39mtopk(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\09_Projects\\04_DeepLearning\\DeepLearning_Undegrad_2025\\utils\\view_helper.py:13\u001b[0m, in \u001b[0;36mview_classify\u001b[1;34m(img, ps, version)\u001b[0m\n\u001b[0;32m     11\u001b[0m ax1\u001b[38;5;241m.\u001b[39mimshow(img\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m     12\u001b[0m ax1\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43max2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbarh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m ax2\u001b[38;5;241m.\u001b[39mset_aspect(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     15\u001b[0m ax2\u001b[38;5;241m.\u001b[39mset_yticks(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[1;32md:\\09_Projects\\04_DeepLearning\\DeepLearning_Undegrad_2025\\.venv\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:2812\u001b[0m, in \u001b[0;36mAxes.barh\u001b[1;34m(self, y, width, height, left, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2693\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2694\u001b[0m \u001b[38;5;124;03mMake a horizontal bar plot.\u001b[39;00m\n\u001b[0;32m   2695\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;124;03m:doc:`/gallery/lines_bars_and_markers/horizontal_barchart_distribution`.\u001b[39;00m\n\u001b[0;32m   2810\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2811\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorizontal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 2812\u001b[0m patches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[43m                   \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m patches\n",
      "File \u001b[1;32md:\\09_Projects\\04_DeepLearning\\DeepLearning_Undegrad_2025\\.venv\\Lib\\site-packages\\matplotlib\\__init__.py:1521\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1526\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1527\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1528\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32md:\\09_Projects\\04_DeepLearning\\DeepLearning_Undegrad_2025\\.venv\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:2572\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2570\u001b[0m         yerr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_dx(yerr, y0, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_yunits)\n\u001b[1;32m-> 2572\u001b[0m x, height, width, y, linewidth, hatch \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2573\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make args iterable too.\u001b[39;49;00m\n\u001b[0;32m   2574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2576\u001b[0m \u001b[38;5;66;03m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[0;32m   2577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32md:\\09_Projects\\04_DeepLearning\\DeepLearning_Undegrad_2025\\.venv\\Lib\\site-packages\\numpy\\lib\\stride_tricks.py:540\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(subok, *args)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m#                  order='C').itviews\u001b[39;00m\n\u001b[0;32m    538\u001b[0m args \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(_m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39msubok) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 540\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m shape \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;66;03m# Common case where nothing needs to be broadcasted.\u001b[39;00m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[1;32md:\\09_Projects\\04_DeepLearning\\DeepLearning_Undegrad_2025\\.venv\\Lib\\site-packages\\numpy\\lib\\stride_tricks.py:422\u001b[0m, in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03msupplied arrays against each other.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# consistently\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args), \u001b[38;5;241m31\u001b[39m):\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;66;03m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 2 with shape (784,) and arg 3 with shape (10,)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from utils import view_helper\n",
    "\n",
    "# Complete the code here: Define architecture\n",
    "\n",
    "\n",
    "# Complete the code here: Build a feed-forward network\n",
    "model =nn.Sequential()\n",
    "\n",
    "\n",
    "# Test an image before training\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "img = images[img_idx]\n",
    "view_helper.view_classify(img.view(1, 28, 28), ps)\n",
    "print(f\"The highest probablity {ps.topk(1).values.item()* 100:.2f}% at class: {ps.topk(1).indices.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 4**: Define Loss Function and Optimizer\n",
    "Set up a suitable loss function and optimizer to train the model.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- **Use Cross-Entropy Loss** as the loss function.\n",
    "    - **Note**: `nn.CrossEntropyLoss()` is commonly used when the model outputs raw logits (i.e., before applying LogSoftmax). It internally applies Softmax and computes the negative log-likelihood loss.\n",
    "    - **`nn.NLLLoss()`** is used when the model outputs log-probabilities (i.e., after applying LogSoftmax). It expects log-probabilities as inputs.\n",
    "\n",
    "- **Select an optimizer**, such as SGD or Adam, and set the learning rate.\n",
    "    - Example:\n",
    "    ```python\n",
    "    criterion = nn.CrossEntropyLoss()  # or nn.NLLLoss() if using LogSoftmax in the model\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# define criterion and optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 5**: Train the Model\n",
    "Train the neural network on the training dataset over multiple epochs.\n",
    "\n",
    "**Task:**\n",
    "- Loop through the training data for a specified number of epochs.\n",
    "- In each epoch:\n",
    "    - Perform a forward pass to compute the predictions.\n",
    "    - Compute the loss for both training and testing.\n",
    "    - Backpropagate the error and update the model weights.\n",
    "    - Track the training/testing loss for each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "# Build the model here. \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 6**: Visualize Results\n",
    "Visualize the model's performance using appropriate plots.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- Plot the training/testing loss curve over epochs.\n",
    "- Display a sample image using **helper module** and print the actual and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(testloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    ps = model(img)\n",
    "\n",
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "view_helper.view_classify(img.view(1, 28, 28), ps)\n",
    "print(f\"The highest probablity: {ps.topk(1).values.item()*100:.2f}% at class: {ps.topk(1).indices.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 7**: Evaluate the Model\n",
    "Assess the model's performance on the testing dataset.\n",
    "**Task:**\n",
    "- Perform predictions on the test dataset.\n",
    "- Generate a confusion matrix to analyze classification errors.\n",
    "- Calculate accuracy by comparing predicted labels with actual labels.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model.eval()\n",
    "pred_class = []\n",
    "actual_class = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:   \n",
    "        images = images.view(images.shape[0], -1)         \n",
    "        ps = model(images)\n",
    "        ## Complete the code here:\n",
    "        pass\n",
    "        \n",
    "\n",
    "pred_class = np.array(pred_class).flatten() \n",
    "actual_class = np.array(actual_class).flatten()               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "class_labels = pd.DataFrame({'Predicted': pred_class, 'Truth_Label': actual_class})\n",
    "class_counts = class_labels['Truth_Label'].value_counts().sort_index()\n",
    "cm = confusion_matrix(actual_class, pred_class)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "TP = np.diag(cm)  \n",
    "FP = np.sum(cm, axis=0) - TP  \n",
    "FN = np.sum(cm, axis=1) - TP  \n",
    "\n",
    "result_df = pd.DataFrame({\"True Positive\": TP, \"False Positive\": FP, \"False Negative\": FN, \"Number_Samples\": class_counts.values})\n",
    "print(f\"Accuracy of the model is: {result_df['True Positive'].sum()/len(class_labels):0.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 8**: Save the Model\n",
    "\n",
    "**Task:**\n",
    "- Save the trained model using PyTorch's `torch.save()` function.\n",
    "- Ensure the model state dictionary (**model.state_dict()**) is saved, as it contains the model parameters.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
