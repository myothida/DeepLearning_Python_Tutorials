{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tutorial 1: Understanding Tensors and Basic Math with Linear Algebra  \n",
    "\n",
    "In this tutorial, we will explore tensors, the building blocks of deep learning, and understand their role in computations. We'll also cover some basic math and linear algebra exercises to strengthen your foundation.  \n",
    "\n",
    "##### What is a Tensor?\n",
    "A tensor is a multi-dimensional array, a generalization of scalars, vectors, and matrices. Tensors allow us to represent data in various dimensions:  \n",
    "\n",
    "- **0D Tensor (Scalar):** A single value.  \n",
    "  Example: `3` or `-7.5`  \n",
    "\n",
    "- **1D Tensor (Vector):** A collection of numbers in a single dimension.  \n",
    "  Example: `[1, 2, 3]`  \n",
    "\n",
    "- **2D Tensor (Matrix):** Numbers arranged in rows and columns.  \n",
    "  \n",
    "- **3D Tensor and Higher Dimension:** A color image (height √ó width √ó RGB channels).  \n",
    "\n",
    "<img src=\"imgs/tensor_examples.svg\" width=600px>\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Exercises  \n",
    "##### Task 01: Create Tensors \n",
    "Use PyTorch to create tensors for the following variables. Ensure that each tensor is initialized with the correct shape and data.\n",
    "\n",
    "- **Features**: Create a tensor with shape (1, 5) (one row and five columns) using random values from a normal distribution.\n",
    "- **Weights**: Create a tensor with shape (1, 5) (one row and five columns), also initialized with random values from a normal distribution.\n",
    "- **Bias**: Create a constant scalar tensor (shape (1, 1)) initialized with a random value from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "### set the random seed to 7\n",
    "torch.manual_seed(7)\n",
    "\n",
    "features = torch.randn((1, 5))\n",
    "weights = torch.randn((1, 5))\n",
    "bias = torch.randn((1, 1))\n",
    "\n",
    "print(\"Features:\", features)\n",
    "print(\"Weights:\", weights)\n",
    "print(\"Bias:\", bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 02: Compute the Values of $ùë¶$ \n",
    "\n",
    "Given the equation, $ y(x, \\omega) = \\omega_0 + \\omega_1x_1 + \\omega_2x_2 + \\omega_3x_3 $\n",
    "Where:  \n",
    "- $x$ represents the features (input data). \n",
    "- $\\omega_i$ represents the weights corresponding to each feature.\n",
    "- $\\omega_0$ represents the bias (a constant added to the output).  \n",
    "\n",
    "### Instructions:  \n",
    "1. Perform **element-wise multiplication** between the `features` tensor and the `weights` tensor.  \n",
    "2. **Sum** the results of the element-wise multiplication.  \n",
    "3. **Add the bias** term to the summed result to compute the final value of $ y $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product =torch.sum(features*weights)\n",
    "y = dot_product + bias\n",
    "print(\"Predicted y:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 03: Reshape and Compute\n",
    "Modify the features tensor to represent a batch of 3 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_m = torch.randn((3, 5))\n",
    "features_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 04: Element-wise Multiplication and Summation\n",
    "Perform element-wise multiplication of `features` and `weights` for the batch of samples created in Task 03. Sum the results row-wise and add the bias to each row. Verify that this matches the result of directly using PyTorch‚Äôs [`torch.mm()`](https://pytorch.org/docs/stable/torch.html#torch.mm) or [`torch.matmul()`](https://pytorch.org/docs/stable/torch.html#torch.matmul)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elementwise_mult = features_m * weights\n",
    "row_sums = torch.sum(elementwise_mult, dim=1)\n",
    "y = row_sums + bias\n",
    "print(\"Row-wise Summed Predictions:\", y)\n",
    "\n",
    "y = torch.matmul(features_m, weights.reshape(5,1))+bias\n",
    "print(\"Matrix Multiplication:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 05: Apply the Sigmoid Function  \n",
    "\n",
    "The **sigmoid function** is commonly used in neural networks to introduce non-linearity. It is defined as:  \n",
    "$\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "where $z$ is the input value.  \n",
    "\n",
    "### Instructions:  \n",
    "1. Create a sigmoid activation function.\n",
    "2. Using the $y$ value computed in **Task 02** as the input $ z $ for the sigmoid function, Compute the sigmoid of $y$ to get the final output.   \n",
    "3. Using the $y$ value computed in **Task 04** as the input $ z $ for the sigmoid function, Compute the sigmoid of $y$ to get the final output.   \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(z):\n",
    "    \"\"\" Sigmoid activation function    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x: torch.Tensor\n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.sum(features * weights) + bias\n",
    "output = activation(y)\n",
    "print(\"Input (y):\", y)\n",
    "print(\"Output (Sigmoid of y):\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.matmul(features_m, weights.reshape(5,1))+bias\n",
    "output = activation(y)\n",
    "print(\"Input (y):\", y)\n",
    "print(\"Output (Sigmoid of y):\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
