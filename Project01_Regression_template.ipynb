{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -U ucimlrepo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "The helper modules for data loading and exploration are already imported. The **data_loader** module loads the \"auto_mpg\" dataset, and **data_explorer** extracts and prints the dataset's metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import data_loader as dl\n",
    "from utils import data_explorer as de\n",
    "import numpy as np\n",
    "\n",
    "data_loader = dl.DataLoader()\n",
    "auto_mpg_data = data_loader.get_dataset(\"auto_mpg\")\n",
    "data_explorer = de.DataExplorer(auto_mpg_data)\n",
    "metadata = data_explorer.describe_data()\n",
    "print(metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 1**: Check for Missing Data\n",
    "\n",
    "Check if there are any missing values in the dataset and removing rows that contain missing data.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- Check for columns (Features) with missing values.  **Hint:** Use the `.isna()` method to identify missing values in the DataFrame, and then use `.sum()` to count them. \n",
    "- Remove the rows with missing values. Hint: Use the `.dropna()` method to remove rows with missing data.\n",
    "- Print out the number of rows before and after cleaning. Expected answer: `398` and `392`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Complete the code here: check missing data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# remove the missing data\n",
    "df = auto_mpg_data.dropna()\n",
    "\n",
    "print(f\"Number of samples Raw dataset: {auto_mpg_data.shape[0]}\")\n",
    "print(f\"Number of samples cleaned dataset: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 2**: Define your target variable (mpg) and features (all other numerical columns), and then split the data into training and testing sets.\n",
    "\n",
    "**Task**:\n",
    "\n",
    "- Define the target (mpg) and select the numerical columns as features.\n",
    "- Split the data into training and testing sets (80% training, 20% testing). **Hint:** Use the `train_test_split` function from the `sklearn.model_selection` module.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = 'mpg'\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "features = numerical_cols[numerical_cols != target]\n",
    "\n",
    "X = df[features].values\n",
    "y = df[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 3**: Preprocess the Data (Scaling)\n",
    "Preprocess the data by normalizing the features using StandardScaler. This is an important step to ensure that the features are on the same scale.\n",
    "\n",
    "**Task**:\n",
    "\n",
    "- Normalize the training and testing features using the StandardScaler. **Hint:** Use the `StandardScaler` from the `sklearn.preprocessing` module to scale the features.  \n",
    "- Convert the data to PyTorch tensors. Hint: Use the `torch.tensor()` function from the PyTorch library to convert `NumPy` arrays to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pre-processing step. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "\n",
    "# Complete the codes here: Normalize the features using the training data only\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Complete the codes here: Convert the data into PyTorch tensors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 4**:  Build the Neural Network Model\n",
    "Define and build the neural network model. For this task, you will use `PyTorch` to define a simple feedforward neural network with one hidden layer. The model will take the normalized features as input and output the predicted fuel efficiency (MPG).\n",
    "\n",
    "\n",
    "**Task**:\n",
    "\n",
    "- Define a neural network model using nn.Sequential() or by creating a custom class that inherits from nn.Module.\n",
    "- The model should include:\n",
    "    - An input layer that matches the number of features.\n",
    "    - At least one hidden layer with a ReLU activation function.\n",
    "    - An output layer with one neuron (since the target is a single continuous value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()        \n",
    "        # Complete the code here: Define the layers (e.g., fully connected layers)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Complete the code here: Define the forward pass\n",
    "        pass\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "input_size = X_train.shape[1]  \n",
    "model = SimpleNN(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 5**:  Train the Neural Network Model\n",
    "Train the neural network model. This involves defining the loss function, specifying the optimizer, and running the training loop. The goal is to minimize the loss (difference between the predicted and actual MPG values) using gradient descent.\n",
    "\n",
    "**Task**:\n",
    "\n",
    "- Define a loss function (e.g., Mean Squared Error for regression tasks).\n",
    "- Choose an optimizer (e.g., Adam, which is commonly used for neural network training).\n",
    "- Write the training loop where the model learns from the training data, calculates the loss, and updates the weights through backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()          \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_test = []\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()  \n",
    "    # Complete the code: Forward pass, compute loss, backward pass, and optimizer step\n",
    "    pass\n",
    "    \n",
    "    # Complete the code: Testing phase (no gradient computation)\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(epochs), loss_values_train, label=\"Training Loss\", color=\"blue\")\n",
    "plt.plot(range(epochs), loss_values_test, label=\"Testing Loss\", color=\"orange\")\n",
    "plt.title(\"Loss Curve Over Training Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 6**:  Evaluate the Model's Performance\n",
    "Evaluate how well the model performs on the train and test dataset that it has not seen before. This helps determine if the model generalizes well to new data or if it overfits to the training data.\n",
    "\n",
    "**Task**:\n",
    "\n",
    "- Use the trained model to make predictions on the train/test data.\n",
    "- Calculate evaluation metrics :Mean Squared Error (MSE).\n",
    "- Visualize the results using plots like predicted vs. actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Complete the code: Make predictions on the test set (turn off gradients)\n",
    "y_pred_test = []\n",
    "pass\n",
    "\n",
    "# Complete the code: Compute and print the Mean Squared Error for the test set\n",
    "pass\n",
    "\n",
    "# Complete the code: Make predictions on the training set (turn off gradients)\n",
    "y_pred_train = []\n",
    "pass\n",
    "\n",
    "# Complete the code: Compute and print the Mean Squared Error for the training set\n",
    "pass\n",
    "\n",
    "# Optional: Convert predictions to NumPy arrays if needed\n",
    "# y_pred_test = ...\n",
    "# y_pred_train = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df_plot_train = pd.DataFrame({\n",
    "    'Actual_train': y_train,\n",
    "    'Predicted_train': y_pred_train.flatten()\n",
    "})\n",
    "min_train = df_plot_train['Actual_train'].min()\n",
    "max_train = df_plot_train['Actual_train'].max()\n",
    "\n",
    "df_plot_test = pd.DataFrame({\n",
    "    'Actual_test': y_test,\n",
    "    'Predicted_test': y_pred_test.flatten()\n",
    "})\n",
    "\n",
    "min_test = df_plot_test['Actual_test'].min()\n",
    "max_test = df_plot_test['Actual_test'].max()\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "sns.scatterplot(data=df_plot_train, x='Actual_train', y='Predicted_train', color = 'blue', marker = 'o', label = 'Training data')\n",
    "sns.scatterplot(data=df_plot_test, x='Actual_test', y='Predicted_test', color = 'green', marker = '^', label = 'Testing data')\n",
    "plt.plot([min(min_train, min_test), max(max_train, max_test)], [min(min_train, min_test), max(max_train, max_test)], color='red', linestyle='--', label='y_pred = y_actual') \n",
    "plt.title('Actual vs Predicted values after Optimization')\n",
    "plt.xlabel('Actual values (y)')\n",
    "plt.ylabel('Predicted values (y_pred)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 7**: Save the Model\n",
    "\n",
    "**Task:**\n",
    "- Save the trained model using PyTorch's `torch.save()` function.\n",
    "- Ensure the model state dictionary (**model.state_dict()**) is saved, as it contains the model parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
