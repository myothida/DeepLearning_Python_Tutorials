{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 08: Building a Convolutional Neural Network (CNN) from Scratch\n",
    "\n",
    "In this tutorial, weâ€™ll learn how to build a Convolutional Neural Network (CNN) from scratch using customized layers created. Please note that the codes are not compuationally efficient and can crash if the computer does not have enough computing power. So, do not run this Tutorial if your comptuer is not ready. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from layers.simpleCNN import SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image_path = \"./data/pet_images/cat_01.jpg\"\n",
    "image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert BGR to RGB (OpenCV loads images in BGR format)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert to PIL Image\n",
    "image_pil = Image.fromarray(image_rgb)\n",
    "\n",
    "# Preprocess the image for a model\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = preprocess(image_pil)\n",
    "\n",
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "denormalized_image = input_tensor * std[:, None, None] + mean[:, None, None]\n",
    "image_np = denormalized_image.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Display both images side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Original Image\n",
    "axes[0].imshow(image_rgb)\n",
    "axes[0].set_title(\"Original RGB Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Transformed Image\n",
    "axes[1].imshow(image_np)\n",
    "axes[1].set_title(\"Transformed Image\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.convolution import Convolution\n",
    "\n",
    "image_tensor = preprocess(image_pil).unsqueeze(0)  \n",
    "\n",
    "conv_layer = Convolution(in_channels=3, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "convolved_image = conv_layer(image_tensor)\n",
    "\n",
    "convolved_image_np = convolved_image.detach().numpy()[0, 0]  \n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(image_rgb)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Convolved Image\n",
    "axes[1].imshow(convolved_image_np, cmap=\"gray\")\n",
    "axes[1].set_title(\"Convolved Image\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.relu import ReLU\n",
    "\n",
    "relu_layer = ReLU()\n",
    "relu_output = relu_layer(convolved_image)\n",
    "relu_output_np = relu_output.detach().numpy()[0, 0] \n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(convolved_image_np, cmap=\"gray\")\n",
    "axes[0].set_title(\"Convolved Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(relu_output_np, cmap=\"gray\")\n",
    "axes[1].set_title(\"ReLU Activated Image\")\n",
    "axes[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.pooling import Pooling\n",
    "\n",
    "pool_layer = Pooling(kernel_size=2, stride=2, pooling_type=\"max\")\n",
    "pooled_image = pool_layer(relu_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved_image_np = convolved_image.detach().numpy()[0, 0]  \n",
    "relu_output_np = relu_output.detach().numpy()[0, 0]  \n",
    "pooled_image_np = pooled_image.detach().numpy()[0, 0] \n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Convolved Image\n",
    "axes[0].imshow(convolved_image_np, cmap=\"gray\")\n",
    "axes[0].set_title(\"Convolved Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# ReLU Output\n",
    "axes[1].imshow(relu_output_np, cmap=\"gray\")\n",
    "axes[1].set_title(\"ReLU Activated Image\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Pooled Image\n",
    "axes[2].imshow(pooled_image_np, cmap=\"gray\")\n",
    "axes[2].set_title(\"Pooled Image (Max Pooling)\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
