{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 04: Saving and Loading Models in PyTorch\n",
    "\n",
    "How to save and load models in PyTorch. PyTorch provides two primary ways to save a model:\n",
    "\n",
    "1. **Saving the entire model**\n",
    "2. **Saving only the model parameters (state_dict)**\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Saving the Entire Model**\n",
    "\n",
    "This approach saves the model architecture along with its parameters, allowing you to reload the model without redefining its structure.\n",
    "\n",
    "##### **Steps**\n",
    "\n",
    "1. Save the model:\n",
    "   ```python\n",
    "   import torch\n",
    "\n",
    "   ## Assuming `model` is your PyTorch model\n",
    "   torch.save(model, 'model.pth')\n",
    "   ```\n",
    "\n",
    "2. Load the model:\n",
    "   ```python\n",
    "   ## Load the entire model\n",
    "   model = torch.load('model.pth')\n",
    "   ```\n",
    "\n",
    "##### **Pros**\n",
    "- Simple to save and load.\n",
    "- No need to redefine the model class when loading.\n",
    "\n",
    "##### **Cons**\n",
    "- Less flexible if you want to modify the model architecture later.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Saving Only the Model Parameters (Recommended)**\n",
    "\n",
    "This method saves only the model's parameters (state_dict), which is a dictionary containing all the learnable parameters and buffers.\n",
    "\n",
    "##### **Steps**\n",
    "\n",
    "1. **Save** the model's state_dict:\n",
    "   ```python\n",
    "   import torch\n",
    "\n",
    "   ## Save model parameters\n",
    "   torch.save(model.state_dict(), 'model_state_dict.pth')\n",
    "   ```\n",
    "\n",
    "2. **Load** the state_dict into the model:\n",
    "   ```python\n",
    "   ## Recreate the model architecture\n",
    "   model = MyModelClass()\n",
    "\n",
    "   ## Load state_dict\n",
    "   model.load_state_dict(torch.load('model_state_dict.pth'))\n",
    "\n",
    "   ## Set the model to evaluation mode (if using for inference)\n",
    "   model.eval()\n",
    "   ```\n",
    "\n",
    "##### **Pros**\n",
    "- Flexible: You can modify the model architecture and then load the saved parameters.\n",
    "- Recommended for most use cases.\n",
    "\n",
    "##### **Cons**\n",
    "- Requires redefining the model class before loading.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"x1\": [2.0, 3.5, 1.8, 2.5, 3.0],\n",
    "    \"x2\": [3000, 4000, 2800, 3500, 3700],\n",
    "    \"x3\": [4, 6, 4, 6, 6],\n",
    "    \"y\": [30, 20, 35, 25, 22]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 2),  \n",
    "    nn.ReLU(),        \n",
    "    nn.Linear(2, 1)   \n",
    ")\n",
    "\n",
    "X = df[[\"x1\", \"x2\", \"x3\"]].values\n",
    "y_actual = df['y'].values\n",
    "X_normalized = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "X_tensor = torch.tensor(X_normalized, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_actual, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  \n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_pred = model(X_tensor)\n",
    "    loss = criterion(y_pred, y_tensor)\n",
    "\n",
    "    # Zero gradients, backward pass, optimizer step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'input_size': 3,  \n",
    "    'output_size': 1,  \n",
    "    'hidden_layers': [2],  \n",
    "    'state_dict': model.state_dict()  \n",
    "}\n",
    "\n",
    "model_path = \"./models/test_model.pth\"\n",
    "torch.save(checkpoint, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Saving with the Optimizer (Optional)**\n",
    "\n",
    "When you need to resume training later, you may also want to save the optimizer's state along with the model.\n",
    "\n",
    "##### **Steps**\n",
    "\n",
    "1. Save the model and optimizer:\n",
    "   ```python\n",
    "   import torch\n",
    "\n",
    "   ## Save model and optimizer state_dict\n",
    "   torch.save({\n",
    "       'model_state_dict': model.state_dict(),\n",
    "       'optimizer_state_dict': optimizer.state_dict(),\n",
    "       'epoch': epoch,\n",
    "       'loss': loss,\n",
    "   }, 'checkpoint.pth')\n",
    "   ```\n",
    "\n",
    "2. Load the checkpoint:\n",
    "   ```python\n",
    "   ## Load the checkpoint\n",
    "   checkpoint = torch.load('checkpoint.pth')\n",
    "\n",
    "   ## Recreate the model and optimizer\n",
    "   model = MyModelClass()\n",
    "   optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "   ## Load state_dicts\n",
    "   model.load_state_dict(checkpoint['model_state_dict'])\n",
    "   optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "   ## Restore other training details\n",
    "   epoch = checkpoint['epoch']\n",
    "   loss = checkpoint['loss']\n",
    "   ```\n",
    "\n",
    "##### **Pros**\n",
    "- Saves both model and training information.\n",
    "- Useful for resuming training.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Additional Tips**\n",
    "\n",
    "1. **Set the model to evaluation mode for inference:**\n",
    "   ```python\n",
    "   model.eval()\n",
    "   ```\n",
    "   This disables layers like dropout and batch normalization during inference.\n",
    "\n",
    "2. **Move the model to the appropriate device:**\n",
    "   ```python\n",
    "   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "   model.to(device)\n",
    "   ```\n",
    "\n",
    "3. **Use meaningful filenames:**\n",
    "   - Include details like the epoch or loss value in the filename, e.g., `model_epoch10_loss0.02.pth`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Summary**\n",
    "\n",
    "- Use `torch.save()` and `torch.load()` for saving and loading models.\n",
    "- Save the entire model for simplicity, but save the state_dict for flexibility.\n",
    "- Include optimizer and training details in checkpoints for resuming training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
