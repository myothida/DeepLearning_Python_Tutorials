{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 13: Building a Vanilla RNN with PyTorch for Sequential Data\n",
    "In this tutorial, weâ€™ll learn how to build a vanilla Recurrent Neural Network (RNN) from scratch using PyTorch. A vanilla RNN is a type of neural network designed to process sequential data such as time series, text, or other ordered data. It has the ability to capture temporal dependencies by using its hidden state that gets updated as it processes each element in the sequence.\n",
    "\n",
    "We will:\n",
    "\n",
    "- Understand the basics of vanilla RNNs.\n",
    "- Build a simple RNN model.\n",
    "- Train the model on a sequential dataset.\n",
    "- Evaluate the model.\n",
    "**Prerequisites**\n",
    "Basic understanding of neural networks and RNNs.\n",
    "Install the following Python libraries: torch, numpy, matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Define layers: input + hidden --> hidden\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        combined = torch.cat((x, hidden), dim=1)\n",
    "        hidden = self.tanh(self.i2h(combined))\n",
    "        output = self.i2o(combined)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VanillaRNN2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(VanillaRNN2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True) \n",
    "        self.i2o = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        last_out = out[:, -1, :]\n",
    "        output = self.i2o(last_out)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden state with zeros\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_simple_regression_data():\n",
    "\n",
    "    data = {\n",
    "        \"x1\": [2.0, 3.5, 1.8, 2.5, 3.0],\n",
    "        \"x2\": [3000, 4000, 2800, 3500, 3700],\n",
    "        \"x3\": [4, 6, 4, 6, 6],\n",
    "        \"y\": [30, 20, 35, 25, 22]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    X = df[[\"x1\", \"x2\", \"x3\"]].values\n",
    "    y_actual = df['y'].values \n",
    "    X_normalized = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "    inputs = torch.tensor(X_normalized, dtype=torch.float32).unsqueeze(1) #add unsqueeeze nn.RNN\n",
    "    targets = torch.tensor(y_actual, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    input_size = 3  # 3 features\n",
    "    hidden_size = 4  \n",
    "    output_size = 1  \n",
    "    num_epochs = 500  \n",
    "\n",
    "    model = VanillaRNN2(input_size, hidden_size, output_size)\n",
    "    criterion = nn.MSELoss()  \n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "    print(f'input size: {inputs.size()}')\n",
    "    print(f'output size: {targets.size()}')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  \n",
    "        hidden = model.init_hidden(batch_size=inputs.size(0))     # 5 samples\n",
    "        optimizer.zero_grad() \n",
    "        output, hidden = model(inputs, hidden)\n",
    "        if epoch ==1:\n",
    "            print(f\"Hidden: {hidden.size()}\")\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 100 == 0:  \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"Output: {output.view(-1).tolist()}\")            \n",
    "            print(f\"Target: {targets.view(-1).tolist()}\")\n",
    "            print(f\"Loss: {loss.item():.4f}\\n\")\n",
    "\n",
    "demo_simple_regression_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
